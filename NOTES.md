# NOTES

## Ключевые решения
- 6 частей корпуса: по 2 книги в каждом .txt, `book_part` стартует 1/3/5 и определяется парсером (`app/indexing/parser.py`).
- Векторка: локальный Chroma `lotr_corpus`, абстракция через `VectorStore`.
- Чанкинг: абзацный разбор с overlap (`chunker.py`), id вида `<book_id>_ch<chapter>_<idx>`.
- RAG: порог по схождению, минимум релевантных чанков, контекст расширяется соседними чанками к процитированным.
- LLM/embeddings: OpenAI (модели из env), запрос в JSON-формате.
- Контейнеризация: Dockerfile на python:3.11-slim, `docker-compose.yml` с томами для `data/vector_store` и `data/corpus`.

## Известные ограничения
- Нет rate limiting и аутентификации, кроме admin-токена на reindex.
- Нет кэширования запросов и результата retrieval.
- Нет детальной наблюдаемости/метрик; логирование базовое.
- Нет тестов для пайплайна и индексации, только ручные проверки.
- Нет graceful-очереди для долгих reindex; операция блокирующая.
- Ответы не стримятся; нет пагинации/лимитов для выдачи контекста.

## Что улучшить при наличии времени
- Рефакторинг: сделать код более читаемым, привести модули к классовой обвязке, строгий typing, явные интерфейсы и зависимости через DI, единый стиль логирования/ошибок, docstrings.
- Лучшие практики: SLA для endpoints, timeouts/retries на LLM, структурные логи, трейс-ид, CI с линтами/тестами, изоляция env для прод/стейдж, pre-commit.
- Retrieval: гибридный поиск (BM25 + векторка), переранжировка, кластеризация близких чанков.
- LLM: использовать нативный structured output `responses.parse`/`response_format`, жёсткая схема JSON.
- Сессии: хранить историю сообщений/чаты, трекинг пользователя, soft-state в Redis/DB.
- Индексация: нормализация корпуса через пайплайн (очистка, дедуп), контроль качества чанков, версия индекса.
- Перфоманс: кэш embeddings, шардинг/пул для Chroma, возможность внешнего стора (Qdrant/PGVector).
